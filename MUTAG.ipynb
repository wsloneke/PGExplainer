{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./codes/forgraph/')\n",
    "from config import args\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_graph_data\n",
    "from models import GCN\n",
    "from metrics import *\n",
    "import numpy as np\n",
    "from Explainer import Explainer\n",
    "from scipy.sparse import coo_matrix\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elr 0.01\n",
      "coff_t0 5.0\n",
      "coff_te 1.0\n",
      "coff_size 0.01\n",
      "coff_ent 0.01\n"
     ]
    }
   ],
   "source": [
    "clip_value_min = -2.0\n",
    "clip_value_max = 2.0\n",
    "args.eepochs = 10\n",
    "args.dataset = \"Mutagenicity\"\n",
    "args.elr = 0.01\n",
    "# args.coff_t0 = 5.0 # For this dataset, high temperature works well.\n",
    "# args.coff_te = 5.0\n",
    "# args.elr = 0.0003\n",
    "# args.coff_size = 0.005\n",
    "# args.coff_ent = 1.0\n",
    "\n",
    "print('elr',args.elr)\n",
    "print('coff_t0',args.coff_t0)\n",
    "print('coff_te',args.coff_te)\n",
    "print('coff_size',args.coff_size)\n",
    "print('coff_ent',args.coff_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "./dataset/Mutagenicity/Mutagenicity_A.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m edge_lists, graph_labels, edge_label_lists, node_label_lists \u001b[38;5;241m=\u001b[39m \u001b[43mget_graph_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/Mutagenicity.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m      3\u001b[0m     original_adjs,original_features,original_labels \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(fin)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\PGExplainer\\./codes/forgraph\\utils.py:18\u001b[0m, in \u001b[0;36mget_graph_data\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     15\u001b[0m file_graph_labels \u001b[38;5;241m=\u001b[39m pri\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph_labels.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m file_node_labels \u001b[38;5;241m=\u001b[39m pri\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_labels.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 18\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     edge_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(file_edge_labels,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:1067\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[1;32m-> 1067\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m     fencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1069\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(fh)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m path)\n",
      "\u001b[1;31mOSError\u001b[0m: ./dataset/Mutagenicity/Mutagenicity_A.txt not found."
     ]
    }
   ],
   "source": [
    "edge_lists, graph_labels, edge_label_lists, node_label_lists = get_graph_data(args.dataset)\n",
    "with open('./dataset/Mutagenicity.pkl','rb') as fin:\n",
    "    original_adjs,original_features,original_labels = pkl.load(fin)\n",
    "\n",
    "# we only consider the mutagen graphs with NO2 and NH2.\n",
    "selected =  []\n",
    "for gid in range(original_adjs.shape[0]):\n",
    "    if np.argmax(original_labels[gid]) == 0 and np.sum(edge_label_lists[gid]) > 0:\n",
    "        selected.append(gid)\n",
    "print('number of mutagen graphs with NO2 and NH2',len(selected))\n",
    "selected_adjs = original_adjs[selected]\n",
    "selected_features = original_features[selected]\n",
    "selected_labels = original_labels[selected]\n",
    "selected_edge_lists = [edge_lists[i] for i in selected]\n",
    "selected_graph_labels=graph_labels[selected]\n",
    "selected_edge_label_lists=[edge_label_lists[i] for i in selected]\n",
    "selected_node_label_lists=[node_label_lists[i] for i in selected]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(input_dim=selected_features.shape[-1], output_dim=selected_labels.shape[1])\n",
    "model.load_weights(args.save_path+args.dataset)\n",
    "\n",
    "selected_adjs_tensor = tf.convert_to_tensor(selected_adjs,dtype=tf.float32)\n",
    "selected_features_tensor = tf.convert_to_tensor(selected_features,dtype=tf.float32)\n",
    "selected_labels_tensor = tf.convert_to_tensor(selected_labels,dtype=tf.float32)\n",
    "selected_output = model.call((selected_features_tensor,selected_adjs_tensor),training=False)\n",
    "selected_acc = accuracy(selected_output, selected_labels_tensor)\n",
    "selected_pred_label = tf.argmax(selected_output, 1)\n",
    "selected_embs = model.getNodeEmb((selected_features_tensor, selected_adjs_tensor), training=False)\n",
    "\n",
    "\n",
    "explainer = Explainer(model=model,nodesize=selected_adjs.shape[1])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.elr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = []\n",
    "preds = []\n",
    "def acc(explainer, gid):\n",
    "    mask = explainer.masked_adj.numpy()\n",
    "    edge_labels = selected_edge_label_lists[gid]\n",
    "    edge_list = selected_edge_lists[gid]\n",
    "    for (r,c),l in list(zip(edge_list,edge_labels)):\n",
    "        if r>c:\n",
    "            reals.append(l)\n",
    "            preds.append(mask[r][c])\n",
    "\n",
    "\n",
    "def explain_graph(fea,emb,adj,label,graphid, needplot=True):\n",
    "    explainer((fea,emb,adj,1.0,label))\n",
    "    acc(explainer,graphid)\n",
    "    if not needplot:\n",
    "        return\n",
    "    after_adj_dense = explainer.masked_adj.numpy()\n",
    "    after_adj = coo_matrix(after_adj_dense)\n",
    "    rcd = np.concatenate(\n",
    "        [np.expand_dims(after_adj.row, -1), np.expand_dims(after_adj.col, -1), np.expand_dims(after_adj.data, -1)], -1)\n",
    "    pos_edges = []\n",
    "    filter_edges = []\n",
    "    edge_weights = np.triu(after_adj_dense).flatten()\n",
    "\n",
    "    sorted_edge_weights = np.sort(edge_weights)\n",
    "    thres_index = max(int(edge_weights.shape[0] - topk), 0)\n",
    "    thres = sorted_edge_weights[thres_index]\n",
    "\n",
    "    for r, c, d in rcd:\n",
    "        r = int(r)\n",
    "        c = int(c)\n",
    "        d = float(d)\n",
    "        if r < c:\n",
    "            continue\n",
    "        if d >= thres:\n",
    "            pos_edges.append((r, c))\n",
    "        filter_edges.append((r, c))\n",
    "\n",
    "    node_label = selected_node_label_lists[graphid]\n",
    "    max_label = np.max(node_label) + 1\n",
    "    nmb_nodes = len(node_label)\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(nmb_nodes))\n",
    "    G.add_edges_from(filter_edges)\n",
    "\n",
    "    pos_edges = [(u, v) for (u, v) in pos_edges if u in G.nodes() and v in G.nodes()]\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "\n",
    "    colors = ['orange','red','lime','green','blue','orchid','darksalmon','darkslategray','gold','bisque','tan','lightseagreen','indigo','navy']\n",
    "\n",
    "    label2nodes = []\n",
    "    for i in range(max_label):\n",
    "        label2nodes.append([])\n",
    "    for i in range(nmb_nodes):\n",
    "        if i in G.nodes():\n",
    "            label2nodes[node_label[i]].append(i)\n",
    "\n",
    "    for i in range(max_label):\n",
    "        node_filter = []\n",
    "        for j in range(len(label2nodes[i])):\n",
    "            node_filter.append(label2nodes[i][j])\n",
    "        nx.draw_networkx_nodes(G, pos,\n",
    "                               nodelist=node_filter,\n",
    "                               node_color=colors[i],\n",
    "                               node_size=300)\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, width=2,  edge_color='grey')\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos,\n",
    "                           edgelist=pos_edges,\n",
    "                           width=7)\n",
    "\n",
    "    plt.title('Graph: '+str(graphid)+' label: '+str(selected_graph_labels[graphid]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    epochs = args.eepochs\n",
    "    t0 = args.coff_t0\n",
    "    t1 = args.coff_te\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        tmp = t0 * np.power(t1 / t0, epoch /epochs )\n",
    "        for gid in range(selected_adjs.shape[0]):\n",
    "            with tf.GradientTape() as tape:\n",
    "                    pred = explainer((selected_features[gid],selected_embs[gid],\\\n",
    "                                      selected_adjs[gid],tmp, selected_labels[gid]),training=True)\n",
    "                    cl = explainer.loss(pred, selected_pred_label[gid])\n",
    "                    loss += cl\n",
    "        train_variables = [para for para in explainer.trainable_variables\n",
    "                           if para.name.startswith('explainer')]\n",
    "        grads = tape.gradient(loss, train_variables)\n",
    "        cliped_grads = [tf.clip_by_value(t, clip_value_min, clip_value_max) for t in grads]\n",
    "        optimizer.apply_gradients(zip(cliped_grads, train_variables))\n",
    "        if epoch%1==0:\n",
    "            print('epoch',epoch,'loss',loss.numpy())\n",
    "            global  reals\n",
    "            global preds\n",
    "            reals =[]\n",
    "            preds =[]\n",
    "            for gid in range(int(selected_adjs.shape[0]/10)):\n",
    "                fea, emb, adj, label = selected_features[gid], selected_embs[gid], selected_adjs[gid], selected_labels[\n",
    "                    gid]\n",
    "                explain_graph(fea, emb, adj, label, gid, needplot=False)\n",
    "\n",
    "            auc = roc_auc_score(reals, preds)\n",
    "            print(auc)\n",
    "\n",
    "#     explainer.save_weights(args.save_path +args.dataset+ 'expaliner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = []\n",
    "preds = []\n",
    "\n",
    "for gid in range(selected_adjs.shape[0]):\n",
    "    fea, emb, adj, label = selected_features[gid], selected_embs[gid], selected_adjs[gid], selected_labels[gid]\n",
    "    explain_graph(fea,emb,adj,label,gid,needplot=False)\n",
    "\n",
    "auc = roc_auc_score(reals, preds)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gid = 0\n",
    "topk = 2\n",
    "fea, emb, adj, label = selected_features[gid], selected_embs[gid], selected_adjs[gid], selected_labels[gid]\n",
    "explain_graph(fea,emb,adj,label,gid,needplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
