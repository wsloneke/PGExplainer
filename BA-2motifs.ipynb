{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./codes/forgraph/')\n",
    "from config import args\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from models import GCN\n",
    "from metrics import *\n",
    "import numpy as np\n",
    "from Explainer import Explainer\n",
    "from scipy.sparse import coo_matrix,csr_matrix\n",
    "import networkx as nx\n",
    "skip = 5\n",
    "topk = 5\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "args.elr = 0.003\n",
    "args.coff_t0=5.0\n",
    "args.coff_t0=1.0\n",
    "args.coff_size = 0.00\n",
    "args.coff_ent = 0.000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/gcnsyn\n"
     ]
    }
   ],
   "source": [
    "print((args.save_path+args.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 25, 10)\n",
      "(1000, 25, 25)\n",
      "model acc 1.0\n"
     ]
    }
   ],
   "source": [
    "with open('./dataset/BA-2motif.pkl','rb') as fin:\n",
    "    adjs,features,labels = pkl.load(fin)\n",
    "\n",
    "model = GCN(input_dim=features.shape[-1], output_dim=labels.shape[1])\n",
    "print(features.shape)\n",
    "print(adjs.shape)\n",
    "model.load_weights(args.save_path+args.dataset)\n",
    "\n",
    "\n",
    "embs = model.getNodeEmb((tf.convert_to_tensor(features,dtype=tf.float32),\\\n",
    "                               tf.convert_to_tensor(adjs,dtype=tf.float32)), training=False)\n",
    "outputs = model.call((tf.convert_to_tensor(features,dtype=tf.float32),\\\n",
    "                            tf.convert_to_tensor(adjs,dtype=tf.float32)),training=False)\n",
    "pred_label = tf.argmax(outputs, 1)\n",
    "\n",
    "acc = accuracy(outputs, labels)\n",
    "print('model acc',acc.numpy())\n",
    "\n",
    "embs = model.getNodeEmb((tf.convert_to_tensor(features,dtype=tf.float32),\\\n",
    "                               tf.convert_to_tensor(adjs,dtype=tf.float32)), training=False)\n",
    "outputs = model.call((tf.convert_to_tensor(features,dtype=tf.float32),\\\n",
    "                            tf.convert_to_tensor(adjs,dtype=tf.float32)),training=False)\n",
    "pred_label = tf.argmax(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 25, 25) (1000, 25, 10) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(adjs.shape, features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25, 20), dtype=float32, numpy=\n",
       "array([[0.01356011, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18774436, 0.18899529, 0.17938729, 0.5015677 , 0.        ,\n",
       "        0.09553387, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06007907, 0.5350698 , 0.        , 0.1180336 , 0.13183358],\n",
       "       [0.        , 0.        , 0.06151724, 0.        , 0.        ,\n",
       "        0.18958965, 0.39040673, 0.09311479, 0.21985553, 0.        ,\n",
       "        0.20867544, 0.0187466 , 0.        , 0.18422475, 0.        ,\n",
       "        0.19162895, 0.22730015, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.04850426, 0.        , 0.        ,\n",
       "        0.1342597 , 0.4279714 , 0.05258246, 0.12992384, 0.        ,\n",
       "        0.17820442, 0.03556078, 0.        , 0.20157142, 0.        ,\n",
       "        0.23509817, 0.14918974, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.13814747, 0.        , 0.        ,\n",
       "        0.1119837 , 0.48986313, 0.        , 0.        , 0.        ,\n",
       "        0.225426  , 0.03390658, 0.        , 0.21867034, 0.        ,\n",
       "        0.23680203, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19802152, 0.36408085, 0.14460003, 0.25448233, 0.        ,\n",
       "        0.19736898, 0.        , 0.        , 0.15588397, 0.        ,\n",
       "        0.19439769, 0.2602712 , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.02423759, 0.        , 0.        ,\n",
       "        0.1588414 , 0.40845308, 0.09525562, 0.22086465, 0.        ,\n",
       "        0.20386864, 0.02519354, 0.        , 0.1852974 , 0.        ,\n",
       "        0.19378681, 0.22584523, 0.        , 0.        , 0.00142043],\n",
       "       [0.        , 0.        , 0.08457907, 0.        , 0.        ,\n",
       "        0.17384468, 0.395168  , 0.05784703, 0.12247597, 0.        ,\n",
       "        0.18516968, 0.03242815, 0.00077391, 0.2172683 , 0.        ,\n",
       "        0.2344746 , 0.14240797, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.13814747, 0.        , 0.        ,\n",
       "        0.1119837 , 0.48986313, 0.        , 0.        , 0.        ,\n",
       "        0.225426  , 0.03390658, 0.        , 0.21867034, 0.        ,\n",
       "        0.23680203, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11735693, 0.        , 0.        ,\n",
       "        0.10040201, 0.49469432, 0.        , 0.05988781, 0.        ,\n",
       "        0.22413181, 0.04943931, 0.        , 0.22852033, 0.        ,\n",
       "        0.23643404, 0.02035649, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.02529798, 0.        , 0.        ,\n",
       "        0.        , 0.64292544, 0.        , 0.        , 0.        ,\n",
       "        0.2149755 , 0.07238003, 0.        , 0.15746136, 0.        ,\n",
       "        0.20435147, 0.        , 0.05609244, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.10126039, 0.        , 0.        ,\n",
       "        0.14250758, 0.4283317 , 0.05770323, 0.0559187 , 0.        ,\n",
       "        0.18744081, 0.03452845, 0.        , 0.2130079 , 0.        ,\n",
       "        0.22160833, 0.05793595, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.10968065, 0.        , 0.        ,\n",
       "        0.1557729 , 0.43239617, 0.0410484 , 0.04660604, 0.        ,\n",
       "        0.19583921, 0.03527363, 0.00606369, 0.22001925, 0.        ,\n",
       "        0.2339358 , 0.0525187 , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11263006, 0.        , 0.        ,\n",
       "        0.13467929, 0.4517823 , 0.04810329, 0.02228981, 0.        ,\n",
       "        0.20602846, 0.0332146 , 0.        , 0.21542048, 0.        ,\n",
       "        0.2229629 , 0.01796484, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.13719955, 0.        , 0.        ,\n",
       "        0.17494716, 0.43374696, 0.02876928, 0.04707614, 0.        ,\n",
       "        0.22254062, 0.04231143, 0.02060977, 0.23892267, 0.        ,\n",
       "        0.22833999, 0.05841925, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.13814747, 0.        , 0.        ,\n",
       "        0.1119837 , 0.48986313, 0.        , 0.        , 0.        ,\n",
       "        0.225426  , 0.03390658, 0.        , 0.21867034, 0.        ,\n",
       "        0.23680203, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15606225, 0.41634208, 0.10544034, 0.24280368, 0.        ,\n",
       "        0.17880452, 0.        , 0.        , 0.14415757, 0.        ,\n",
       "        0.21145478, 0.2404243 , 0.        , 0.        , 0.00638215],\n",
       "       [0.        , 0.        , 0.13814747, 0.        , 0.        ,\n",
       "        0.1119837 , 0.48986313, 0.        , 0.        , 0.        ,\n",
       "        0.225426  , 0.03390658, 0.        , 0.21867034, 0.        ,\n",
       "        0.23680203, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11263006, 0.        , 0.        ,\n",
       "        0.13467929, 0.4517823 , 0.04810329, 0.02228981, 0.        ,\n",
       "        0.20602846, 0.0332146 , 0.        , 0.21542048, 0.        ,\n",
       "        0.2229629 , 0.01796484, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.13814747, 0.        , 0.        ,\n",
       "        0.1119837 , 0.48986313, 0.        , 0.        , 0.        ,\n",
       "        0.225426  , 0.03390658, 0.        , 0.21867034, 0.        ,\n",
       "        0.23680203, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11340946, 0.        , 0.        ,\n",
       "        0.17061745, 0.4346769 , 0.03152486, 0.02920086, 0.        ,\n",
       "        0.2038113 , 0.03423322, 0.01561565, 0.224663  , 0.        ,\n",
       "        0.24514712, 0.04305933, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.03871753, 0.        , 0.        ,\n",
       "        0.03792083, 0.57689357, 0.00844002, 0.25758418, 0.        ,\n",
       "        0.3253466 , 0.03884582, 0.        , 0.21614955, 0.        ,\n",
       "        0.14818963, 0.1752074 , 0.03179109, 0.        , 0.05183097],\n",
       "       [0.        , 0.        , 0.00345123, 0.        , 0.        ,\n",
       "        0.        , 0.6338324 , 0.        , 0.15472747, 0.        ,\n",
       "        0.28670365, 0.0617188 , 0.        , 0.17412281, 0.        ,\n",
       "        0.17334443, 0.08619545, 0.07237785, 0.07369789, 0.09093788],\n",
       "       [0.        , 0.        , 0.03193133, 0.        , 0.        ,\n",
       "        0.06860813, 0.552356  , 0.        , 0.22219431, 0.        ,\n",
       "        0.28769332, 0.04816875, 0.        , 0.23229532, 0.        ,\n",
       "        0.19929324, 0.16402246, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.03193136, 0.        , 0.        ,\n",
       "        0.06860821, 0.552356  , 0.        , 0.22219428, 0.        ,\n",
       "        0.2876933 , 0.04816876, 0.        , 0.23229538, 0.        ,\n",
       "        0.19929329, 0.16402245, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.00345119, 0.        , 0.        ,\n",
       "        0.        , 0.6338324 , 0.        , 0.1547275 , 0.        ,\n",
       "        0.28670365, 0.06171879, 0.        , 0.17412275, 0.        ,\n",
       "        0.1733444 , 0.08619542, 0.07237793, 0.07369799, 0.09093788]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 25, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        ...,\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1]],\n",
       "\n",
       "       [[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        ...,\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1]],\n",
       "\n",
       "       [[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        ...,\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        ...,\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1]],\n",
       "\n",
       "       [[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        ...,\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1]],\n",
       "\n",
       "       [[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        ...,\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "        [0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.setting==1:\n",
    "    allnodes = [i for i in range(0,100)]\n",
    "elif args.setting==2:\n",
    "    allnodes = [i for i in range(0,100)]\n",
    "    allnodes.extend([i for i in range(500,600)])\n",
    "elif args.setting==3:\n",
    "    allnodes=[i for i in range(1000)]\n",
    "explainer = Explainer(model=model,nodesize=adjs.shape[1])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.elr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(adj,insert):\n",
    "    mask = explainer.masked_adj.numpy()\n",
    "    adj = coo_matrix(adj)\n",
    "    for r,c in list(zip(adj.row,adj.col)):\n",
    "        if r>=insert and r<insert+skip and c>=insert and c<insert+skip:\n",
    "            reals.append(1)\n",
    "        else:\n",
    "            reals.append(0)\n",
    "        preds.append(mask[r][c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_graph(gid):\n",
    "    fea,emb,adj,label,graphid = features[gid], embs[gid], adjs[gid], labels[gid], gid\n",
    "    explainer((fea,emb,adj,1.0,label))\n",
    "    insert = 20\n",
    "    acc(adj,insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    global preds\n",
    "    global reals\n",
    "    preds = []\n",
    "    reals = []\n",
    "    for gid in allnodes:\n",
    "        explain_graph(gid)\n",
    "    auc = roc_auc_score(reals,preds)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    epochs = 10\n",
    "    t0 = args.coff_t0\n",
    "    t1 = args.coff_te\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        loss = 0\n",
    "        tmp = float(t0 * np.power(t1 / t0, epoch /epochs))\n",
    "        train_instances = [ins for ins in range(adjs.shape[0])]\n",
    "        np.random.shuffle(train_instances)\n",
    "        for gid in train_instances:\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = explainer((features[gid],embs[gid],adjs[gid],tmp, labels[gid]),training=True)\n",
    "                loss += explainer.loss(pred, labels[gid])\n",
    "        train_variables = [para for para in explainer.trainable_variables]\n",
    "        grads = tape.gradient(loss, train_variables)\n",
    "        optimizer.apply_gradients(zip(grads, train_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_best = -np.inf\n",
    "best_k = None\n",
    "k = 20\n",
    "for i in range(0, k):\n",
    "    train()\n",
    "    auc = test()\n",
    "    print(i)\n",
    "    if auc > auc_best:\n",
    "        auc_best = auc\n",
    "        best_k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc_best)\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
